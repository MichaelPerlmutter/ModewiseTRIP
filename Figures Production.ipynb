{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures\n",
    "\n",
    "This notebook is used to generate the (revised) figures in https://export.arxiv.org/abs/2109.10454\n",
    "It requires the results from the various numeric experiments, which were broken out to many jobs and then merged into three different csv files. The final figure was not included in the print, but is a convergence plot for single runs of TIHT using both two step and vectorized approaches at various ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This spreadsheet contains the merged results for all trials where $n=40$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_40 = pd.read_csv('results/dim40_trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fourier and gaussian views for convenience and define the intermediate dimensions which will coresspond to different lines on the plots. Define label and marker dictionaries that are used across all the subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourier = df_40[df_40[\"meas\"]==\"Fourier\"]\n",
    "df_gaussian = df_40[df_40[\"meas\"]==\"Gaussian\"]\n",
    "m1_40 = df_40[\"intermediate dimension\"].unique()\n",
    "intm_label_dict = {200:r\"$m=200$\",250:r\"$m=250$\",300:r\"$m=300$\",1:\"vec\"}\n",
    "marker_dict = {200:\"--+\",250:\"--x\",300:\"--.\",1:\"--*\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Reliability\n",
    "\n",
    "2x2 subplot, columns share same rank, rows share same measurement type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(8,6))\n",
    "#Rank 3s on the left\n",
    "r=3 \n",
    "for m1 in m1_40:\n",
    "    ax1.plot(df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"target_dim\"], df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"percent_recovered\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "    ax3.plot(df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"target_dim\"], df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"percent_recovered\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "ax1.set_title(\"Gaussian, $r=(3,3,3,3)$\")\n",
    "ax3.set_title(\"SORS, $r=(3,3,3,3)$\")\n",
    "\n",
    "#Rank 5s on the right\n",
    "r=5\n",
    "for m1 in m1_40:\n",
    "    ax2.plot(df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"target_dim\"], df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"percent_recovered\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "    ax4.plot(df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"target_dim\"], df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"percent_recovered\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "ax2.set_title(\"Gaussian, $r=(5,5,5,5)$\")\n",
    "ax4.set_title(\"SORS, $r=(5,5,5,5)$\")\n",
    "    \n",
    "#Every subplot has the same labels and legend location\n",
    "for ax in fig.get_axes():\n",
    "    ax.set(xlabel=\"target dimension\")\n",
    "    ax.set(ylabel=\"percent recovered\")\n",
    "    ax.legend(loc=4)\n",
    "    \n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig('figures/fractions_40.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Speed\n",
    "\n",
    "2x2 subplot, columns share same rank, rows share same measurement type, now we consider average number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(8,6))\n",
    "\n",
    "#Rank 3s on left\n",
    "r=3\n",
    "for m1 in m1_40:\n",
    "    ax1.plot(df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"target_dim\"], df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"avg # iters\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "    ax3.plot(df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"target_dim\"], df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"avg # iters\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "ax1.set_title(\"Gaussian, $r=(3,3,3,3)$\")\n",
    "ax3.set_title(\"SORS, $r=(3,3,3,3)$\")\n",
    "\n",
    "#Rank 5s on the right\n",
    "r=5\n",
    "for m1 in m1_40:\n",
    "    ax2.plot(df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"target_dim\"], df_gaussian[(df_gaussian[\"intermediate dimension\"] == m1) & (df_gaussian[\"r\"] == r)][\"avg # iters\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "    ax4.plot(df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"target_dim\"], df_fourier[(df_fourier[\"intermediate dimension\"] == m1) & (df_fourier[\"r\"] == r)][\"avg # iters\"], marker_dict[m1],label=intm_label_dict[m1])\n",
    "ax2.set_title(\"Gaussian, $r=(5,5,5,5)$\")\n",
    "ax4.set_title(\"SORS, $r=(5,5,5,5)$\")\n",
    "\n",
    "#Every subplot gets the same axis labels and legend location\n",
    "for ax in fig.get_axes():\n",
    "    ax.set(xlabel=\"target dimension\")\n",
    "    ax.set(ylabel=\"average iterations\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    \n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig('figures/num-iterations_40.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger Tensor with Rank Study\n",
    "\n",
    "For these results, we use only SORs measurements since its impractical as currently implemented to generate large, dense guassian matrices. We also have a third set of results which show the average relative error for the same problem setting but after a fixed number of iterations (500); this compared with the last figure suggests that at some rank, for a given final sketching dimension, the algorithm is highly likelt to get stuck in flat regions /non-global optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_96 = pd.read_csv(\"results/dim96_trials.csv\")\n",
    "df_fixed = pd.read_csv(\"results/dim96_fixed_iteration_trials.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modes switch betweeb vectorized and two-step. In this data set, final and intermediate sketching dimensions are 32,768 with 2048 or 65536 with 4096. Label and marker dictionaries are used across the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df_96[\"mode\"].unique()\n",
    "m1_96 = df_96[\"target_dim\"].unique()\n",
    "label_dict = {\"VEC65536\":\"vec,65k\",\"TWOSTEP65536\":\"2-step,65k\",\"VEC32768\":\"vec,32k\",\"TWOSTEP32768\":\"2-step,32k\"}\n",
    "marker_dict = {\"VEC65536\":\"--+\",\"TWOSTEP65536\":\"--x\",\"VEC32768\":\"--.\",\"TWOSTEP32768\":\"--*\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "for t in m1_96:\n",
    "    for m in modes:\n",
    "        key = m+str(t)\n",
    "        ax1.plot(df_96[(df_96[\"mode\"] == m) & (df_96['target_dim']==t)][\"r\"], df_96[(df_96[\"mode\"] == m) & (df_96['target_dim']==t)][\"percent_recovered\"], marker_dict[key],label=label_dict[key])\n",
    "\n",
    "ax1.set_title(\"Recovery reliabilty\")\n",
    "ax1.set(xlabel=\"Rank\", ylabel=\"percent recovered\")\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "\n",
    "for t in m1_96:\n",
    "    for m in modes:\n",
    "        key = m+str(t)\n",
    "        ax2.plot(df_96[(df_96[\"mode\"] == m) & (df_96['target_dim']==t)][\"r\"], df_96[(df_96[\"mode\"] == m) & (df_96['target_dim']==t)][\"avg # iters\"], marker_dict[key],label=label_dict[key])\n",
    "\n",
    "ax2.set_title(\"Convergence speed\")\n",
    "ax2.set(xlabel=\"Rank\", ylabel=\"average iterations \")\n",
    "ax2.legend()\n",
    "\n",
    "for t in m1_96:\n",
    "    for m in modes:\n",
    "        key = m+str(t)\n",
    "        ax3.plot(df_fixed[(df_fixed[\"mode\"] == m) & (df_fixed['target_dim']==t)][\"r\"], df_fixed[(df_fixed[\"mode\"] == m) & (df_fixed['target_dim']==t)][\"avg error\"], marker_dict[key],label=label_dict[key])\n",
    "\n",
    "ax3.set_title(\"Average relative error\")\n",
    "ax3.set(xlabel=\"Rank\", ylabel=\"average relative rrror\", yscale='log')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig('figures/dim96.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not evident exactly from these results that simply allowing for more iterations will result in the algorithm to converge for the larger ranks. Although that is difficult to demonstrate definitively, a look at the loss over iterations for various ranks shows the likely failure mode. Below we load the errors from a single, typical run of the $n=96$ case at ranks 2,4,6 and 8 for both vectorized and two step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_trajectory = np.load(\"errors_96.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels for which rows of the array correspond to which runs\n",
    "\n",
    "error_labels = {0:r\"vec,$m_0=65k,r=2$\",1:r\"2-step,$m_0=65k,r=2$\",\n",
    "               2:r\"vec,$m_0=65k,r=4$\",3:r\"2-step,$m_0=65k,r=4$\",\n",
    "               4:r\"vec,$m_0=65k,r=6$\",5:r\"2-step,$m_0=65k,r=6$\",\n",
    "               6:r\"vec,$m_0=65k,r=8$\",7:r\"2-step,$m_0=65k,r=8$\"}\n",
    "\n",
    "#intensity of the color will denote rank. Darker means higher rank\n",
    "my_reds = plt.cm.Reds(np.linspace(0.25, 1, 4))\n",
    "my_blues = plt.cm.Blues(np.linspace(0.25, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each row, if its vectorized\n",
    "for i,row in enumerate(error_trajectory):\n",
    "    if i%2==0:\n",
    "        plt.plot(row,label=error_labels[i],color=my_reds[i//2])\n",
    "        \n",
    "    else:\n",
    "        plt.plot(row,label=error_labels[i],color=my_blues[(i-1)//2])\n",
    "\n",
    "plt.title('Typical Error ')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('relative error')\n",
    "red_patch = mpatches.Patch(color=my_reds[1], label='vec')\n",
    "blue_patch = mpatches.Patch(color=my_blues[1], label='2-step')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the flat regions of stagnation for the $r=6$ that eventually it breaks out of whereas for $r=8$ it may be the case the algorithm is stuck"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
