{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly import decomposition\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.linalg import dft\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_low_rank(n,r):\n",
    "    #torch.manual_seed(0)\n",
    "    #np.random.seed(0)\n",
    "    C=np.random.normal(0,1,size=r)\n",
    "    C=tl.tensor(C)\n",
    "    C.shape\n",
    "    X=C\n",
    "\n",
    "    U=[]\n",
    "    for i in range(len(n)):\n",
    "        M=np.random.normal(0,1,size=(n[i],n[i]))\n",
    "        u,sigma,v=np.linalg.svd(M)\n",
    "        U.append(u[:,0:r[i]])\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        X=tl.tenalg.mode_dot(X,U[i],i)\n",
    "    return X\n",
    "\n",
    "def low_rank_approx(tensor,r):\n",
    "    #torch.manual_seed(0)\n",
    "\n",
    "    core, factors = tl.decomposition.tucker(tensor.numpy(), r)\n",
    "    answer = torch.tensor(tl.tucker_to_tensor([core, factors]))\n",
    "    return answer\n",
    "    \n",
    "def vectorize(X):\n",
    "    x=X.numpy()\n",
    "    x=x.reshape(-1)\n",
    "    return x\n",
    "\n",
    "def tensorize(x,n):\n",
    "    return torch.tensor(x.reshape(n))\n",
    "\n",
    "def modewise_measurements(cur_tensor, measurements):\n",
    "    cur_tensor_array = cur_tensor.numpy()\n",
    "    cur_tensor_array = tl.tenalg.multi_mode_dot(cur_tensor_array, measurements)\n",
    "    return torch.tensor(cur_tensor_array)\n",
    "\n",
    "def matrix_modewise_measurements(cur_tensor, measurements):\n",
    "    cur_tensor_array = cur_tensor.numpy()\n",
    "    int_array = np.matmul(measurements[0], cur_tensor_array)\n",
    "    cur_tensor_array = np.matmul(int_array, measurements[1].T)\n",
    "    return torch.tensor(cur_tensor_array)\n",
    "\n",
    "def two_step_measurements_original(X,A,Afinal):\n",
    "    return np.matmul(Afinal,vectorize(matrix_modewise_measurements(X, A)))\n",
    "\n",
    "def two_step_lift(y, A, AT, Afinal, mintermediate, n):\n",
    "    ybig=np.matmul(Afinal.conj().T, y)\n",
    "    Ybig=tensorize(ybig, mintermediate)\n",
    "    Xpullback= matrix_modewise_measurements(Ybig, AT)\n",
    "    return torch.reshape(Xpullback, n)\n",
    "\n",
    "def relative_error(true,guess,first_loss):\n",
    "    return (np.linalg.norm(true - guess)/first_loss)\n",
    "\n",
    "\n",
    "def create_kfjl_meas(dim, k):\n",
    "    if dim<k:\n",
    "        raise ValueError(\"dim is less than k, matrix needs to be tall and skinny\")\n",
    "        \n",
    "    #np.random.seed(0)\n",
    "    m=dft(dim)/np.sqrt(dim)\n",
    "    vec=np.random.choice([-1,1],dim)\n",
    "    m = np.matmul(m, np.diag(vec))\n",
    "    m = np.sqrt(dim/k)*m[:int(k), :]\n",
    "    return m\n",
    "\n",
    "def create_gaussian_meas(dim, k):\n",
    "    np.random.seed(0)\n",
    "    return np.sqrt(1/k)*np.random.normal(0.0, 1.0, [k, dim])\n",
    "\n",
    "def reshaped_dimension(n1,d):\n",
    "    n=n1*np.ones(d,dtype=int)\n",
    "    nn=((n[:d//2]).prod(),(n[d//2:]).prod())\n",
    "    n = tuple(n)\n",
    "    return n,nn\n",
    "\n",
    "def reshaped_rank(r1,d):\n",
    "    r=r1*np.ones(d,dtype=int)\n",
    "    rp=((r[:d//2]).prod(),(r[d//2:]).prod())\n",
    "    return r,rp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_tensors(n1,d,r1,num_samples):\n",
    "\n",
    "    #ensure same data every time\n",
    "    #torch.manual_seed(0)\n",
    "    \n",
    "    #reshaped dimensions\n",
    "    n,nn=reshaped_dimension(n1,d)\n",
    "    r,rp=reshaped_rank(r1,d)\n",
    "\n",
    "    #Create random low rank tensor and reshape it\n",
    "    XX = []\n",
    "    reshaped_XX = []\n",
    "    for j in range(num_samples):\n",
    "        X=torch.tensor(random_low_rank(n, r), dtype=torch.float64)\n",
    "        reshaped_X=torch.reshape(X, nn)\n",
    "        XX.append(X)\n",
    "        reshaped_XX.append(reshaped_X)\n",
    "        \n",
    "    return XX, reshaped_XX\n",
    "\n",
    "#XX, reshaped_XX = generate_tensors(n1,d,r1,num_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modewise Fourier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mw_fourier_meas_measurements(n1,d,m1,r1):\n",
    "def mw_measurements(reshaped_XX,m1,num_samples,meas=\"Fourier\"):\n",
    "\n",
    "    ## Re-running this window with different compression ratios resamples measurement matrices only\n",
    "    #torch.manual_seed(0)\n",
    "  \n",
    "    nn=tuple(reshaped_XX[0].shape)\n",
    "    \n",
    "    # Compute and print out intermediate dimensions\n",
    "    mi=np.array([m1 for i in range(len(nn))])\n",
    "    m_first=mi.prod()\n",
    "    m_second = m_first\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    #Compute Fourier operators\n",
    "    if meas==\"Fourier\":\n",
    "        A = [create_kfjl_meas(nn[i], mi[i]) for i in range(len(nn))]\n",
    "    elif meas==\"Gaussian\":\n",
    "        A = [create_gaussian_meas(nn[i], mi[i]) for i in range(len(nn))]\n",
    "    else:\n",
    "        raise ValueError(\"Set meas to either 'Fourier' or 'Gaussian'\")\n",
    "    \n",
    "    AT=[A[i].conj().T for i in range(len(A))]\n",
    "\n",
    "    yy = []\n",
    "    # Compute measurements\n",
    "    for j in range(num_samples):\n",
    "        y = matrix_modewise_measurements(reshaped_XX[j], A)\n",
    "        yy.append(y)\n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    #record time\n",
    "    avg_meas_time=(stop - start)/num_samples \n",
    "    \n",
    "    return A,AT,yy, avg_meas_time   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MWTIHT(n1,d,r1,m1,num_samples=100,meas=\"Fourier\",mu=.1,N_iter=1000,accuracy=.001):\n",
    "    \n",
    "\n",
    "    #parameters\n",
    "    #mu, N_iter =.1, 1000\n",
    "    #accuracy = 0.001\n",
    "    good_runs = 0\n",
    "    total_time = 0\n",
    "    total_iters = 0\n",
    "    r,rp=reshaped_rank(r1,d)\n",
    "    n,nn=reshaped_dimension(n1,d)\n",
    "    \n",
    "    #generate tensors and measurements\n",
    "    torch.manual_seed(0)\n",
    "    X0 = torch.randn(n)\n",
    "    XX, reshaped_XX = generate_tensors(n1,d,r1,num_samples)\n",
    "    A,AT,yy,time=mw_measurements(reshaped_XX,m1,num_samples,meas)\n",
    "    \n",
    "    Losses=[[1] for _ in range(num_samples)]\n",
    "    # Run recovery algorithm\n",
    "    for j in range(num_samples):\n",
    "        #print(j)\n",
    "        start = timeit.default_timer()\n",
    "        X_iter=torch.clone(X0)\n",
    "        first_loss = np.linalg.norm(XX[j] - X_iter)\n",
    "        i = 0\n",
    "        while Losses[j][-1] > accuracy and i < N_iter:\n",
    "            i += 1 \n",
    "            Losses[j].append(relative_error(true=XX[j], guess=X_iter, first_loss=first_loss))\n",
    "            X_iter_reshaped=torch.reshape(X_iter, nn)\n",
    "            first_step = matrix_modewise_measurements(X_iter_reshaped, A)\n",
    "            Z = yy[j] - first_step\n",
    "\n",
    "            Z = torch.reshape(matrix_modewise_measurements(Z, AT), n)    \n",
    "            Y_iter=X_iter+mu*Z\n",
    "    \n",
    "            X_iter=low_rank_approx(Y_iter, r)\n",
    "        stop = timeit.default_timer()\n",
    "        #plt.plot(range(len(Losses[j])), Losses[j])   \n",
    "        #if i == N_iter:\n",
    "        #    print(\"Not converged\")\n",
    "        if i<N_iter:\n",
    "            good_runs += 1\n",
    "            total_time += stop - start\n",
    "            total_iters += i\n",
    "            #print(\"Converged!\")\n",
    "            #print('Number of iterations: ', i)\n",
    "            #print('Final loss: ', Losses[j][-1])\n",
    "    if good_runs != 0:\n",
    "        Convergence_percent=100*good_runs/num_samples\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= total_time/good_runs\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= total_iters/good_runs \n",
    "   \n",
    "    else:\n",
    "        Convergence_percent=0\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= np.inf\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= N_iter\n",
    "   \n",
    "    return Convergence_percent, Average_recovery_time, Average_number_of_iterations\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Fourier Measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vectorized_meas_measurements(XX,m1,num_samples,meas):\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "\n",
    "    n=tuple(XX[0].shape)\n",
    "    #n=np.ones(d)*n1\n",
    "    #r=np.ones(d)*r1\n",
    "\n",
    "    \n",
    "    mi=np.array([int(n[0]) for i in range(len(n))])\n",
    "    m_first=mi.prod()\n",
    "    m_second = m1**2\n",
    "    #print(\"dim initial \", np.array(n).prod())\n",
    "    #print(\"dim after comp \", m_second)\n",
    "\n",
    "    yy = []\n",
    "    start = timeit.default_timer()\n",
    "    if meas==\"Fourier\":\n",
    "        Afinal=create_kfjl_meas(m_first, m_second)\n",
    "    elif meas==\"Gaussian\":\n",
    "        Afinal=create_gaussian_meas(m_first, m_second)\n",
    "    else:\n",
    "        raise ValueError(\"Set meas to either 'Fourier' or 'Gaussian'\")\n",
    "    \n",
    "    Afconj = Afinal.conj().T\n",
    "    for j in range(num_samples):\n",
    "        y =  np.matmul(Afinal,vectorize(XX[j]))\n",
    "        yy.append(y)\n",
    "    stop = timeit.default_timer()\n",
    "    #print(y.shape)\n",
    "    #print('Measurement time: ', (stop - start)/num_samples)\n",
    "    avg_meas_time=(stop - start)/num_samples\n",
    "    return Afinal,Afconj,yy, avg_meas_time\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VECTIHT(n1,d,r1,m1,num_samples=100,meas=\"Fourier\",mu=.1,N_iter=1000,accuracy=.001):\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "\n",
    "    XX, reshaped_XX = generate_tensors(n1,d,r1,num_samples)\n",
    "    Afinal,Afconj,yy, avg_meas_time=vectorized_meas_measurements(XX,m1,num_samples,meas)\n",
    "\n",
    "    Losses3 = [[1] for _ in range(num_samples)]\n",
    "    #mu, N_iter =.1, 1000\n",
    "    #accuracy = 0.001\n",
    "\n",
    "    good_runs = 0\n",
    "    total_time = 0\n",
    "    total_iters = 0\n",
    "\n",
    "    n=tuple(XX[0].shape)\n",
    "    r,rp=reshaped_rank(r1,d)\n",
    "\n",
    "    X0 = torch.randn(n)\n",
    "\n",
    "    # Run recovery algorithm\n",
    "    for j in range(num_samples):\n",
    "        #print(j)\n",
    "        start = timeit.default_timer()\n",
    "        X_iter=torch.clone(X0)\n",
    "        first_loss = np.linalg.norm(XX[j] - X_iter)\n",
    "        i = 0\n",
    "        while Losses3[j][-1] > accuracy and i < N_iter:\n",
    "            i += 1 \n",
    "            Losses3[j].append(relative_error(true=XX[j] ,guess=X_iter, first_loss=first_loss))\n",
    "            measX = np.matmul(Afinal,vectorize(X_iter))\n",
    "            Z = yy[j] - measX\n",
    "     \n",
    "            Z = torch.reshape(torch.tensor(np.matmul(Afconj, Z)), n)\n",
    "            Y_iter=X_iter+mu*Z\n",
    "    \n",
    "            X_iter=low_rank_approx(Y_iter, r)\n",
    "        stop = timeit.default_timer()\n",
    "    \n",
    "        #plt.plot(range(len(Losses3[j])), Losses3[j])   \n",
    "        if i < N_iter:\n",
    "            good_runs += 1\n",
    "            total_time += stop - start\n",
    "            total_iters += i\n",
    "            #print(\"Converged!\")\n",
    "            #print('Number of iterations: ', i)\n",
    "    '''if good_runs != 0:\n",
    "        print('\\n')\n",
    "        print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        print('Average recovery time: ', total_time/good_runs) \n",
    "        print('Average number of iterations: ', total_iters/good_runs) \n",
    "    else:\n",
    "        print(\"Never converged :(\")'''\n",
    "        \n",
    "    if good_runs != 0:\n",
    "        Convergence_percent=100*good_runs/num_samples\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= total_time/good_runs\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= total_iters/good_runs \n",
    "   \n",
    "    else:\n",
    "        Convergence_percent=0\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= np.inf\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= N_iter\n",
    "   \n",
    "    return Convergence_percent, Average_recovery_time, Average_number_of_iterations\n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def two_step_measurements(XX,reshaped_XX,m1_intermediate,m2,num_samples,meas):\n",
    "\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "\n",
    "    n=tuple(XX[0].shape)\n",
    "    nn=tuple(reshaped_XX[0].shape)\n",
    "\n",
    "    # Compute and print out intermediate dimensions\n",
    "    mi=np.array([m1_intermediate for i in range(len(nn))])\n",
    "    m_first=mi.prod()\n",
    "    m_second = m2\n",
    "\n",
    "    #print(\"dim initial \", np.array(nn).prod())\n",
    "    #print(\"dim after 1 comp \", m_first)\n",
    "    #print(\"dim after 2 comp \", m_second)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    #Compute Fourier intermediate operators\n",
    "    if meas==\"Fourier\":\n",
    "        A = [create_kfjl_meas(nn[i], mi[i]) for i in range(len(nn))]\n",
    "        Afinal=create_kfjl_meas(m_first, m_second)\n",
    "    elif meas==\"Gaussian\":\n",
    "        A = [create_gaussian_meas(nn[i], mi[i]) for i in range(len(nn))]\n",
    "        Afinal=create_gaussian_meas(m_first, m_second)\n",
    "    else:\n",
    "        raise ValueError(\"Set meas to either 'Fourier' or 'Gaussian'\")\n",
    "    AT=[A[i].conj().T for i in range(len(A))]\n",
    "    Afconj = Afinal.conj().T\n",
    "\n",
    "    yy = []\n",
    "    # Compute measurements\n",
    "    for j in range(num_samples):\n",
    "        y1=vectorize(matrix_modewise_measurements(reshaped_XX[j], A))\n",
    "        y = np.matmul(Afinal,y1)\n",
    "        \n",
    "        yy.append(y)\n",
    "    #print('target dimension: ', y.shape) \n",
    "    stop = timeit.default_timer()\n",
    "    #print('Measurement time: ', (stop - start)/num_samples) \n",
    "    average_time=(stop - start)/num_samples\n",
    "    return A,AT,Afinal,Afconj,yy,average_time\n",
    "#A,AT,Afinal,Afconj,yy,average_time=two_step_fourier_meas_measurements(XX,reshaped_XX,m1_intermediate,m2,num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TWOSTEPTIHT(n1,d,r1,m1_intermediate,m2,num_samples=100,meas=\"Fourier\",mu=.1,N_iter=1000,accuracy=.001):\n",
    "\n",
    "    XX, reshaped_XX = generate_tensors(n1,d,r1,num_samples)\n",
    "    n=tuple(XX[0].shape)\n",
    "    nn=tuple(reshaped_XX[0].shape)\n",
    "    mi=np.array([m1_intermediate for i in range(len(nn))])\n",
    "\n",
    "\n",
    "    A,AT,Afinal,Afconj,yy,average_time=two_step_measurements(XX,reshaped_XX,m1_intermediate,m2,num_samples,meas)\n",
    "\n",
    "\n",
    "    Losses2=[[1] for _ in range(num_samples)]\n",
    "    #mu, N_iter =.1, 1000\n",
    "    #accuracy = 0.001\n",
    "    good_runs = 0\n",
    "    total_time = 0\n",
    "    total_iters = 0\n",
    "\n",
    "    r,rp=reshaped_rank(r1,d)\n",
    "\n",
    "    X0 = torch.randn(n)\n",
    "\n",
    "    # Run recovery algorithm\n",
    "    for j in range(num_samples):\n",
    "        #print(j)\n",
    "        start = timeit.default_timer()\n",
    "        X_iter=torch.clone(X0)\n",
    "        first_loss = np.linalg.norm(XX[j] - X_iter)\n",
    "        i = 0\n",
    "        while Losses2[j][-1] > 0.001 and i < N_iter:\n",
    "            i += 1 \n",
    "            Losses2[j].append(relative_error(true=XX[j],guess=X_iter, first_loss=first_loss))\n",
    "            X_iter_reshaped=torch.reshape(X_iter, nn)\n",
    "            first_step = matrix_modewise_measurements(X_iter_reshaped, A)\n",
    "\n",
    "            measX = np.matmul(Afinal,vectorize(first_step))\n",
    "            Z = yy[j] - measX\n",
    "            Z = tensorize(np.matmul(Afinal.conj().T, Z), mi)\n",
    "\n",
    "            Z = torch.reshape(matrix_modewise_measurements(Z, AT), n)    \n",
    "            Y_iter=X_iter+mu*Z\n",
    "            X_iter=low_rank_approx(Y_iter, r)\n",
    "        \n",
    "        stop = timeit.default_timer()\n",
    "        #plt.plot(range(len(Losses2[j])), Losses2[j])   \n",
    "        if i < N_iter:\n",
    "            good_runs += 1\n",
    "            total_time += stop - start\n",
    "            total_iters += i\n",
    "            #print(\"Converged!\")\n",
    "            #print('Number of iterations: ', i)\n",
    "            #print('Final loss: ', Losses[j][-1])\n",
    "    '''if good_runs != 0:\n",
    "        print('\\n')\n",
    "        print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        print('Average recovery time: ', total_time/good_runs) \n",
    "        print('Average number of iterations: ', total_iters/good_runs) \n",
    "    else:\n",
    "        print(\"Never converged :(\")'''\n",
    "    \n",
    "    if good_runs != 0:\n",
    "        Convergence_percent=100*good_runs/num_samples\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= total_time/good_runs\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= total_iters/good_runs \n",
    "   \n",
    "    else:\n",
    "        Convergence_percent=0\n",
    "        #print('\\n')\n",
    "        #print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        #print('Average recovery time: ', total_time/good_runs)\n",
    "        Average_recovery_time= np.inf\n",
    "        #print('Average number of iterations: ', total_iters/good_runs)\n",
    "        Average_number_of_iterations= N_iter\n",
    "   \n",
    "    return Convergence_percent, Average_recovery_time, Average_number_of_iterations\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments\n",
    "\n",
    "The run_trial function can run any of the three functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(n1,d,r1,m1,m1_intermediate,num_samples,mode,meas):\n",
    "    \n",
    "    #seeding\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    #hyperparameters\n",
    "    mu, N_iter =.1, 1000\n",
    "    accuracy = 0.001\n",
    "\n",
    "    #fix random seed here \n",
    "    if mode==\"MW\":\n",
    "        return MWTIHT(n1,d,r1,m1,num_samples,meas,mu,N_iter,accuracy)\n",
    "    elif mode==\"VEC\":\n",
    "        return  VECTIHT(n1,d,r1,m1,num_samples,meas,mu,N_iter,accuracy)\n",
    "    elif mode ==\"TWOSTEP\":\n",
    "        #m2 in TWOSTEP corresponds to m1^2\n",
    "        return TWOSTEPTIHT(n1,d,r1,m1_intermediate,m1*m1,num_samples,meas,mu,N_iter,accuracy)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Mode: Please select MW, VEC, or TWOSTEP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: Loop over parameters and print many results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Dimensions and Parameters\\nn1, d = 5, 4 #Here we always set d'=d//2 (i.e. kappa=2)\\nm1=20\\n\\nm1_intermediate = 22   #compression factors (after first compression have dimenions m1_intermediate^2)\\n\\n\\nr1=2\\nnum_samples = 1\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Dimensions and Parameters\n",
    "n1, d = 5, 4 #Here we always set d'=d//2 (i.e. kappa=2)\n",
    "m1=20\n",
    "\n",
    "m1_intermediate = 22   #compression factors (after first compression have dimenions m1_intermediate^2)\n",
    "\n",
    "\n",
    "r1=2\n",
    "num_samples = 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for m1 in [20]:\\n    for mode in [\"VEC\",\"MW\",\"TWOSTEP\"]:\\n        print(mode,m1,run_trial(n1,d,r1,m1,m1_intermediate,num_samples,mode,\"Fourier\"))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for m1 in [20]:\n",
    "    for mode in [\"VEC\",\"MW\",\"TWOSTEP\"]:\n",
    "        print(mode,m1,run_trial(n1,d,r1,m1,m1_intermediate,num_samples,mode,\"Fourier\"))\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Store Results  in DataFrame and Save  to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 28, 26, 24, 22, 20, 18]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[30-2*x for x in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store parameters in a list\n",
    "ns=[10]\n",
    "rs=[2]\n",
    "target_dims=[int(x**2) for x in [40,38,36,34,32]]\n",
    "ds=[4]\n",
    "m1smallss=[80**2]\n",
    "modes=[\"VEC\"]\n",
    "num_samples=100\n",
    "meases=[\"Fourier\"]\n",
    "params=[(n1,d,r1,t,mode,meas) for n1 in ns for d in ds for t in target_dims for r1 in rs for mode in modes for meas in meases]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 2, 1600, 'VEC', 'Fourier')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikep/.local/lib/python3.6/site-packages/tensorly/tucker_tensor.py:323: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if rank == 'same':\n"
     ]
    }
   ],
   "source": [
    "#empty lists \n",
    "resultns=[] #\n",
    "resultrs=[]#\n",
    "resulttars=[]#\n",
    "resultpercents=[]#\n",
    "resultds=[]#\n",
    "resultiters=[]#\n",
    "resulttimes=[]#\n",
    "resultintermediates=[]\n",
    "resultmodes=[]#\n",
    "resultmeases=[]\n",
    "\n",
    "for p in params:\n",
    "    print(p)\n",
    "    m1=(int(np.sqrt(p[3])))\n",
    "    if p[4] == \"TWOSTEP\":\n",
    "        \n",
    "        #This is a cheap hack\n",
    "        if p[0]==5:\n",
    "            m1_intermediate=22\n",
    "        else:\n",
    "            m1_intermediate=22\n",
    "\n",
    "        Convergence_percent, Average_recovery_time, Average_number_of_iterations=run_trial(p[0],p[1],p[2],m1,m1_intermediate,num_samples,p[4],p[5])\n",
    "        resultintermediates.append(m1_intermediate**2)\n",
    "    else:\n",
    "        Convergence_percent, Average_recovery_time, Average_number_of_iterations=run_trial(p[0],p[1],p[2],m1,1,num_samples,p[4],p[5])\n",
    "        resultintermediates.append(\"NA\")\n",
    "    \n",
    "    #add parameter settings to a list\n",
    "    resultns.append(p[0])\n",
    "    resultds.append(p[1])\n",
    "    resultrs.append(p[2])\n",
    "    resulttars.append(p[3])\n",
    "    resultmodes.append(p[4])\n",
    "    resultmeases.append(p[5])\n",
    "    resultiters.append(Average_number_of_iterations)\n",
    "    resulttimes.append(Average_recovery_time)\n",
    "    resultpercents.append(Convergence_percent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Create dataframe\n",
    "result_dict={\n",
    "    \"n\":resultns,\n",
    "    \"r\":resultrs,\n",
    "    \"target_dim\":resulttars,\n",
    "    \"percent_recovered\":resultpercents,\n",
    "    \"avg # iters\": resultiters,\n",
    "    \"avg time\": resulttimes,\n",
    "    \"intermediate dimension\":resultintermediates,\n",
    "    \"mode\":resultmodes,\n",
    "    \"meas\":resultmeases\n",
    "}\n",
    "results=pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"n\",\"r\",\"mode\",\"target_dim\",\"percent_recovered\",\"avg # iters\",\"avg time\",\"intermediate dimension\"]\n",
    "results=results[cols]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%m%d%H%M\")\n",
    "\n",
    "name=\"LONEPINEresults\"+str(meases[0])+str(modes[0])+dt_string+\".csv\"\n",
    "\n",
    "results.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
